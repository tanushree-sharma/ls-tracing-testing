{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14cb8b72",
   "metadata": {},
   "source": [
    "# Testing wrap_openai + openai responses api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c90f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_04b2c2ac9c9601a90068e451eaa79c81a28fc39ef257703841', created_at=1759793642.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_04b2c2ac9c9601a90068e451eb60c081a2a53cabb14d31bebd', content=[ResponseOutputText(annotations=[], text='Once upon a time, a gentle unicorn named Luna danced under a starlit sky, her silver horn shimmering with magic. She found a lonely puppy and, with a touch of her horn, filled his dreams with joy and adventure. Every night after, the two friends explored sparkling meadows together, safe and happy beneath the moonâ€™s soft glow.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=18, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=71, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=89), user=None, billing={'payer': 'developer'}, store=True)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "client = wrap_openai(openai.Client())\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4.1\",\n",
    "  input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28416bce",
   "metadata": {},
   "source": [
    "# P0\n",
    "\n",
    "Input rendering does not look right: https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&tab=0&peek=6f9488d7-d727-4571-86b0-7472602c9243&peeked_trace=6f9488d7-d727-4571-86b0-7472602c9243\n",
    "\n",
    "Input contains this openai.Omit object. Should we be dropping these on ingest?\n",
    "\n",
    "Padding seems off with Additional fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76a1373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# web search tool\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input=\"What's the latest news about AI?\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5bbeb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Cat_August_2010-4.jpg/2880px-Cat_August_2010-4.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Display the image from the provided URL\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Cat_August_2010-4.jpg/2880px-Cat_August_2010-4.jpg\"\n",
    "display(Image(url=url, width=400))\n",
    "\n",
    "response_multimodal = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": \n",
    "                 \"Come up with keywords related to the image, and search on the web using the search tool for any news related to the keywords\"\n",
    "                 \", summarize the findings and cite the sources.\"},\n",
    "                {\"type\": \"input_image\", \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Cat_August_2010-4.jpg/2880px-Cat_August_2010-4.jpg\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    tools=[\n",
    "        {\"type\": \"web_search\"}\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ab90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 1. Define a list of callable tools for the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_horoscope\",\n",
    "        \"description\": \"Get today's horoscope for an astrological sign.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sign\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"An astrological sign like Taurus or Aquarius\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sign\"],\n",
    "        },\n",
    "    },\n",
    "        {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_retrograde_planets\",\n",
    "        \"description\": \"Get today's retrograde planets for an astrological sign.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sign\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Curernt date\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"date\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "def get_retrograde_planets(date):\n",
    "    return f\"Retrograde planets for {date}: Mercury, Venus, and Mars.\"\n",
    "\n",
    "def get_horoscope(sign):\n",
    "    return f\"{sign}: Next Tuesday you will befriend a baby otter.\"\n",
    "\n",
    "# Create a running input list we will add to over time\n",
    "input_list = [\n",
    "    {\"role\": \"user\", \"content\": \"What is my horoscope? I am an Aquarius.\"}\n",
    "]\n",
    "\n",
    "# 2. Prompt the model with tools defined\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    ")\n",
    "\n",
    "# Save function call outputs for subsequent requests\n",
    "input_list += response.output\n",
    "\n",
    "for item in response.output:\n",
    "    if item.type == \"function_call\":\n",
    "        if item.name == \"get_horoscope\":\n",
    "            # 3. Execute the function logic for get_horoscope\n",
    "            horoscope = get_horoscope(json.loads(item.arguments))\n",
    "            \n",
    "            # 4. Provide function call results to the model\n",
    "            input_list.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": json.dumps({\n",
    "                  \"horoscope\": horoscope\n",
    "                })\n",
    "            })\n",
    "\n",
    "print(\"Final input:\")\n",
    "print(input_list)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    instructions=\"Respond only with a horoscope generated by a tool.\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    ")\n",
    "\n",
    "# 5. The model should be able to give a response!\n",
    "print(\"Final output:\")\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(\"\\n\" + response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055dca8e",
   "metadata": {},
   "source": [
    "# P0\n",
    "\n",
    "UI doesnt show the tool that was called in the \"Tools\" section. IIRC we show a \"Called\" (or something similar to this) tag normally \n",
    "\n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&tab=0&peek=ca327adc-95e6-4ef7-bc0a-03d817ba9deb&peeked_trace=ca327adc-95e6-4ef7-bc0a-03d817ba9deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0484a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"mcp\",\n",
    "            \"server_label\": \"dmcp\",\n",
    "            \"server_description\": \"A Dungeons and Dragons MCP server to assist with dice rolling.\",\n",
    "            \"server_url\": \"https://dmcp-server.deno.dev/sse\",\n",
    "            \"require_approval\": \"never\",\n",
    "        },\n",
    "    ],\n",
    "    input=\"Roll 2d4+1\",\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18551565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instructions = \"\"\"\n",
    "You are a personal math tutor. When asked a math question, \n",
    "write and run code using the python tool to answer the question.\n",
    "\"\"\"\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"code_interpreter\",\n",
    "            \"container\": {\"type\": \"auto\"}\n",
    "        }\n",
    "    ],\n",
    "    instructions=instructions,\n",
    "    input=\"I need to solve the equation 3x + 11 = 14. Can you help me?\",\n",
    ")\n",
    "\n",
    "print(resp.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce7113",
   "metadata": {},
   "source": [
    "# P1\n",
    "\n",
    "code interpreter tool doesnt render under \"Tools\" section \n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&tab=0&peek=83371525-e6fa-44f5-98fe-beccacfc4813&peeked_trace=83371525-e6fa-44f5-98fe-beccacfc4813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf350e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## image generation tool \n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"Generate an image of gray tabby cat hugging an otter with an orange scarf\",\n",
    "    tools=[{\"type\": \"image_generation\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b206324",
   "metadata": {},
   "source": [
    "# P2\n",
    "\n",
    "Mostly renders well. There's an empty AI messages that shows up though\n",
    "\n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&tab=0&peek=210da83b-c7b6-4a1e-9816-a0772d454fd9&peeked_trace=210da83b-c7b6-4a1e-9816-a0772d454fd9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24109f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "client = wrap_openai(openai.Client())\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    "    text_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "event = response.output_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b60cbd",
   "metadata": {},
   "source": [
    "# P1 \n",
    "\n",
    "We dont show text_format as the output schema for the llm call \n",
    "\n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&tab=0&peek=695a031e-d7dc-45aa-a756-553384fea5ac&peeked_trace=695a031e-d7dc-45aa-a756-553384fea5ac\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

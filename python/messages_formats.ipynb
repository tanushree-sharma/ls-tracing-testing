{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14cb8b72",
   "metadata": {},
   "source": [
    "# Testing langchain format rendering in LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fbb222",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install dotenv\n",
    "%pip install langchain-openai\n",
    "%pip install langchain-anthropic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c90f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "model = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\")\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40236b3",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&peek=e3fcd134-f8b1-4323-b9e7-c78cafcd6d14&peeked_trace=e3fcd134-f8b1-4323-b9e7-c78cafcd6d14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing tool calls\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = model.bind_tools(tools)\n",
    "\n",
    "query = \"What is 3 * 12? Please use the tools to answer the question.\"\n",
    "\n",
    "llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d097292",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&tab=0&peek=8f6013be-b1a2-4895-a7a7-31ab73878f4f&peeked_trace=8f6013be-b1a2-4895-a7a7-31ab73878f4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "526aeff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can’t directly edit the file here, but below are ready-to-use, precise instructions and AI prompts so you (or any editor/AI tool) can create a highly “intense” version of this image. I included two stylistic options (Vibrant HDR and Dramatic Moody) and exact slider values, plus an img2img prompt for Stable Diffusion / other image-to-image tools.\n",
      "\n",
      "Option A — Vibrant, high‑dynamic-range, ultra‑detailed (recommended)\n",
      "- Goal: punchy colors, deep contrast, lots of texture/detail, warm highlights and teal shadows for a cinematic look.\n",
      "\n",
      "Lightroom / Camera Raw exact settings\n",
      "- Basic: Exposure 0.00 (leave), Contrast +25, Highlights -40, Shadows +25, Whites +15, Blacks -15\n",
      "- Presence: Texture +30, Clarity +35, Dehaze +25, Vibrance +30, Saturation +8\n",
      "- Tone Curve: slight S (lift shadows slightly, push highlights up)\n",
      "- HSL:\n",
      "  - Reds Saturation +5, Luminance +5\n",
      "  - Oranges Saturation +8, Luminance +6\n",
      "  - Yellows Saturation +10, Luminance +8\n",
      "  - Greens Saturation +18, Luminance +12\n",
      "  - Aquas Saturation +10, Luminance +8\n",
      "  - Blues Saturation +18, Luminance -5\n",
      "- Split Toning / Color Grading:\n",
      "  - Highlights: Hue ~40 (warm gold), Sat 25\n",
      "  - Shadows: Hue ~200–220 (teal), Sat 18\n",
      "  - Balance: +15 toward highlights\n",
      "- Detail: Sharpening Amount 70, Radius 1.0, Detail 25, Masking 40\n",
      "- Effects: Post‑Crop Vignetting -8, Dehaze further +10 if needed\n",
      "- Local adjustments:\n",
      "  - Graduated filter on sky: Exposure -0.6, Clarity +40, Dehaze +20, Saturation +10\n",
      "  - Radial filter around boardwalk: Exposure +0.4, Clarity +20, Sharpness +20 to draw the eye\n",
      "\n",
      "Photoshop (alternate) quick recipe\n",
      "1. Duplicate background layer.\n",
      "2. Apply Camera Raw Filter with the Lightroom settings above.\n",
      "3. Create a new layer, set Blend Mode to Overlay, fill 50% gray, use Dodge (midtones/highlights) on the boardwalk and Burn (midtones/shadows) to deepen grass shadows — subtle.\n",
      "4. High‑Pass sharpen: merge visible copy (Ctrl/Cmd+Alt+Shift+E), Filter > Other > High Pass 1.5–2.5 px, set layer to Overlay/Soft Light at 60–80% opacity.\n",
      "5. Add slight vignette using Levels or Curves on a black layer with a large soft mask painted out in center.\n",
      "6. (Optional) Add warm sun flare on horizon with a soft low‑opacity orange brush set to Screen.\n",
      "\n",
      "Mobile (Snapseed)\n",
      "- Tune Image: Ambiance +20, Brightness 0, Contrast +20, Saturation +10\n",
      "- Details: Structure +30, Sharpening +25\n",
      "- HDR Scape: Style: HDR, Strength ~40\n",
      "- Selective: brighten boardwalk +15, increase Structure +10\n",
      "- Curves: S-curve for contrast\n",
      "- Vignette: -10\n",
      "\n",
      "Option B — Dramatic, moody, cinematic (stormy/intense)\n",
      "- Lower overall exposure slightly, deepen blues/teals in sky, increase contrast, desaturate greens slightly, increase clarity and texture, maybe darken edges and add heavy vignette.\n",
      "Lightroom tips: Exposure -0.2, Contrast +40, Highlights -60, Shadows +10, Blacks -30, Clarity +50, Dehaze +35, Vibrance +10, Greens Saturation -10, Blues Saturation +10, Split tone shadows deeper teal, heavy vignette -25.\n",
      "\n",
      "AI img2img prompt (Stable Diffusion / AUTOMATIC1111)\n",
      "- Prompt (paste in prompt box):\n",
      "  \"An intensely vivid, hyper‑realistic photograph of a wooden boardwalk through tall green marsh grass under a dramatic streaked blue sky, golden-hour warm highlights and teal shadows, ultra-detailed texture, high dynamic range (HDR), deep contrast, crisp sharpness, volumetric light, slight sun flare on the horizon, cinematic color grading, 35mm low perspective, photorealistic\"\n",
      "- Negative prompt:\n",
      "  \"lowres, blurry, deformed, artifact, watermark, oversmoothed\"\n",
      "- Suggested parameters:\n",
      "  - Denoising Strength: 0.35–0.5 (keep composition)\n",
      "  - Steps: 30–45\n",
      "  - Sampler: Euler a or DPM++ 2M Karras\n",
      "  - CFG Scale: 7.0–9.0\n",
      "  - Resolution: same as original (or upscale later)\n",
      "  - Seed: random or fixed for reproducibility\n",
      "- If you want even more intensity, increase Vibrance/Saturation in a 2nd pass (or apply 2-stage img2img: mild then stronger).\n",
      "\n",
      "Midjourney prompt variant\n",
      "- Prompt:\n",
      "  \"photorealistic wooden boardwalk through marsh grass, intense HDR colors, cinematic teal and gold color grade, dramatic streaked sky, volumetric light, ultra-detailed, high contrast, sharp texture --ar 3:2 --v 5 --stylize 250\"\n",
      "- Add \"--quality 2\" if you want extra compute.\n",
      "\n",
      "Which would you like me to make: (A) Vibrant HDR or (B) Dramatic Moody? I can produce a final prompt tailored further, or—if you want—give a step-by-step Photoshop action file or Lightroom preset text you can import.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "import httpx\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Fetch image data\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Generate an intense version of this image:\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"source_type\": \"base64\",\n",
    "            \"data\": image_data,\n",
    "            \"mime_type\": \"image/jpeg\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "response = model.invoke([message])\n",
    "print(response.text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch PDF data - anthropic \n",
    "\n",
    "import base64\n",
    "\n",
    "import httpx\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Fetch PDF data\n",
    "pdf_url = \"https://pdfobject.com/pdf/sample.pdf\"\n",
    "pdf_data = base64.b64encode(httpx.get(pdf_url).content).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# Pass to LLM\n",
    "llm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Describe the document:\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"file\",\n",
    "            \"source_type\": \"base64\",\n",
    "            \"data\": pdf_data,\n",
    "            \"mime_type\": \"application/pdf\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "response = llm.invoke([message])\n",
    "print(response.text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91169ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch PDF data - openAI \n",
    "\n",
    "import base64\n",
    "\n",
    "import httpx\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Fetch PDF data\n",
    "pdf_url = \"https://pdfobject.com/pdf/sample.pdf\"\n",
    "pdf_data = base64.b64encode(httpx.get(pdf_url).content).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Describe the document:\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"file\",\n",
    "            \"filename\": \"sample.pdf\",\n",
    "            \"source_type\": \"base64\",\n",
    "            \"data\": pdf_data,\n",
    "            \"mime_type\": \"application/pdf\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "response = model.invoke([message])\n",
    "print(response.text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6fa063",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&tab=0&peek=23ba2249-c874-4707-ad21-5fa6bb60edc3&peeked_trace=23ba2249-c874-4707-ad21-5fa6bb60edc3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ab724",
   "metadata": {},
   "source": [
    "## gap: we don't render tool messages in inputs correctly \n",
    "\n",
    "{\"messages\": [     {\n",
    "      \"role\": \"tool\",\n",
    "      \"tool_call_id\": \"call_1\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"{\\\"temperature\\\": \\\"18°C\\\", \\\"condition\\\": \\\"Sunny\\\"}\"\n",
    "        }\n",
    "      ]\n",
    "    }]}\n",
    "\n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&searchModel=%7B%22filter%22%3A%22eq%28is_root%2C+true%29%22%7D&peek=059319e3-7e7b-4c4a-8a8c-52e909166514&peeked_trace=059319e3-7e7b-4c4a-8a8c-52e909166514\n",
    "\n",
    "Compared to tool messages we show as outputs: \n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&searchModel=%7B%22filter%22%3A%22search%28%5C%22Sunny%5C%22%29%22%2C%22searchFilter%22%3A%22eq%28is_root%2C+true%29%22%7D&peek=641aea60-6edd-4449-83ce-9525a47d86b3&peeked_trace=641aea60-6edd-4449-83ce-9525a47d86b3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a593c7",
   "metadata": {},
   "source": [
    "## gap: we don't render JSON for tool message text\n",
    "\n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&searchModel=%7B%22filter%22%3A%22eq%28is_root%2C+true%29%22%7D&peek=059319e3-7e7b-4c4a-8a8c-52e909166514&peeked_trace=059319e3-7e7b-4c4a-8a8c-52e909166514"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ffb896",
   "metadata": {},
   "source": [
    "## open question: whats the right format for reasoning? \n",
    "\n",
    "this doesnt work:\n",
    "  \"messages\": [{\n",
    "  \"role\": \"assistant\",\n",
    "  \"content\": [\n",
    "    {\n",
    "      \"type\": \"reasoning\",\n",
    "      \"summary\": [\n",
    "        { \"text\": \"Break the expression into two integers and multiply.\" }\n",
    "      ],\n",
    "    },\n",
    "    { \"type\": \"text\", \"text\": \"3×12 = 36.\" }\n",
    "  ]\n",
    "}\n",
    "  ]\n",
    "\n",
    "\n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%22feedback_stats%22%3Afalse%2C%22reference_example%22%3Afalse%2C%22start_time%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22error%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Afalse%2C%22last_queued_at%22%3Afalse%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Afalse%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22reference_example_id%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&runtab=0&peek=affb4bdf-d207-4d6b-9cd0-3bebef63fb32&peeked_trace=affb4bdf-d207-4d6b-9cd0-3bebef63fb32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af26869",
   "metadata": {},
   "source": [
    "## open question: rendering streamed chunks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ea3d4",
   "metadata": {},
   "source": [
    "## open question: how to send up a list of tools for the model to call?\n",
    "\n",
    "this doesnt work:  \n",
    "outputs5 = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"reasoning\",\n",
    "          \"summary\": [\n",
    "            { \"text\": \"Break the expression into two integers and multiply.\" }\n",
    "          ]\n",
    "        },\n",
    "        { \"type\": \"text\", \"text\": \"3×12 = 36.\" }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"tools\": [\n",
    "      {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "          \"name\": \"add\",\n",
    "          \"description\": \"Add two integers.\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"a\": { \"description\": \"First integer\", \"type\": \"integer\" },\n",
    "              \"b\": { \"description\": \"Second integer\", \"type\": \"integer\" }\n",
    "            },\n",
    "            \"required\": [\"a\", \"b\"]\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "          \"name\": \"multiply\",\n",
    "          \"description\": \"Multiply two integers.\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"a\": { \"description\": \"First integer\", \"type\": \"integer\" },\n",
    "              \"b\": { \"description\": \"Second integer\", \"type\": \"integer\" }\n",
    "            },\n",
    "            \"required\": [\"a\", \"b\"]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "inputs = {\"messages\": [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Describe the document:\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"file\",\n",
    "            \"source_type\": \"base64\",\n",
    "            \"data\": pdf_data,\n",
    "            \"mime_type\": \"application/pdf\",\n",
    "        },\n",
    "    ],\n",
    "}]}\n",
    "\n",
    "inputs2 = {\"messages\": [     {\n",
    "      \"role\": \"tool\",\n",
    "      \"tool_call_id\": \"call_1\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"{\\\"temperature\\\": \\\"18°C\\\", \\\"condition\\\": \\\"Sunny\\\"}\"\n",
    "        }\n",
    "      ]\n",
    "    }]}\n",
    "\n",
    "\n",
    "outputs = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\",\n",
    "      \"tool_calls\": [\n",
    "        {\n",
    "          \"id\": \"call_PrOTnQHHzub0MSOYhWvodbaP\",\n",
    "          \"type\": \"function\",\n",
    "          \"function\": {\n",
    "            \"name\": \"multiply\",\n",
    "            \"arguments\": \"{\\\"a\\\":{\\\"temperature\\\": \\\"18°C\\\", \\\"condition\\\": \\\"Sunny\\\"},\\\"b\\\":12}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "outputs2 = {\n",
    "  \"messages\": [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "    { \"role\": \"user\", \"content\": \"What’s 3×12?\" },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\",\n",
    "      \"tool_calls\": [\n",
    "        {\n",
    "          \"id\": \"call_1\",\n",
    "          \"type\": \"function\",\n",
    "          \"function\": {\n",
    "            \"name\": \"multiply\",\n",
    "            \"arguments\": \"{\\\"a\\\":3,\\\"b\\\":12}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"role\": \"tool\",\n",
    "      \"tool_call_id\": \"call_1\",\n",
    "      \"name\": \"multiply\",\n",
    "      \"content\": \"{\\\"result\\\":36}\"\n",
    "    },\n",
    "\n",
    "    { \"role\": \"assistant\", \"content\": \"3×12 = 36.\" }\n",
    "  ]\n",
    "}\n",
    "\n",
    "outputs3 = {\n",
    "  \"messages\": [\n",
    "    {\"role\":\"user\",\"content\":\"What’s 3×12?\"},\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\",\n",
    "      \"tool_calls\": [\n",
    "        {\n",
    "          \"id\": \"call_1\",\n",
    "          \"type\": \"function\",\n",
    "          \"function\": { \"name\": \"multiply\", \"arguments\": \"{\\\"a\\\":3,\\\"b\\\":12}\" }\n",
    "        }\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"reasoning\": {\n",
    "          \"tokens\": 64,\n",
    "          \"summary\": \"Parsed expression and selected multiply(a=3,b=12).\",\n",
    "          \"effort\": \"medium\"\n",
    "        }\n",
    "      },\n",
    "      \"additional_kwargs\": {\n",
    "        \"provider_reasoning\": { \"items\": [] }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "outputs4 = {\n",
    "  \"messages\": [{\n",
    "  \"role\": \"assistant\",\n",
    "  \"content\": [\n",
    "    {\n",
    "      \"type\": \"reasoning\",\n",
    "      \"summary\": [\n",
    "        { \"text\": \"Break the expression into two integers and multiply.\" }\n",
    "      ],\n",
    "    },\n",
    "    { \"type\": \"text\", \"text\": \"3×12 = 36.\" }\n",
    "  ]\n",
    "}\n",
    "  ]\n",
    "}\n",
    "\n",
    "#messages with tools as metadata. this didnt work \n",
    "outputs5 = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"reasoning\",\n",
    "          \"summary\": [\n",
    "            { \"text\": \"Break the expression into two integers and multiply.\" }\n",
    "          ]\n",
    "        },\n",
    "        { \"type\": \"text\", \"text\": \"3×12 = 36.\" }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"tools\": [\n",
    "      {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "          \"name\": \"add\",\n",
    "          \"description\": \"Add two integers.\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"a\": { \"description\": \"First integer\", \"type\": \"integer\" },\n",
    "              \"b\": { \"description\": \"Second integer\", \"type\": \"integer\" }\n",
    "            },\n",
    "            \"required\": [\"a\", \"b\"]\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "          \"name\": \"multiply\",\n",
    "          \"description\": \"Multiply two integers.\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"a\": { \"description\": \"First integer\", \"type\": \"integer\" },\n",
    "              \"b\": { \"description\": \"Second integer\", \"type\": \"integer\" }\n",
    "            },\n",
    "            \"required\": [\"a\", \"b\"]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def llm_raw(inputs):\n",
    "    return outputs\n",
    "\n",
    "\n",
    "llm_raw(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c64cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"alice\",  # Optional: identify different users\n",
    "    id=\"msg_123\",  # Optional: unique identifier for tracing\n",
    ")\n",
    "\n",
    "response = model.invoke([human_msg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bc6f42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'assistant',\n",
       "   'content': '',\n",
       "   'tool_calls': [{'id': 'call_1',\n",
       "     'type': 'function',\n",
       "     'function': {'name': 'identify_dog_breed',\n",
       "      'arguments': '{\"image_url\": \"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\"}'}}]},\n",
       "  {'role': 'tool',\n",
       "   'tool_call_id': 'call_1',\n",
       "   'content': [{'type': 'text', 'text': '{\"breed\": \"Black Labrador\"}'}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'This looks like a Black Labrador.'}]}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"id\": \"msg_123\",\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What breed is this dog?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image\",\n",
    "          \"source_type\": \"url\",\n",
    "          \"url\": \"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\",\n",
    "          \"mime_type\": \"image/jpeg\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "outputs = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\",\n",
    "      \"tool_calls\": [\n",
    "        {\n",
    "          \"id\": \"call_1\",\n",
    "          \"type\": \"function\",\n",
    "          \"function\": {\n",
    "            \"name\": \"identify_dog_breed\",\n",
    "            \"arguments\": \"{\\\"image_url\\\": \\\"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\\\"}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"tool\",\n",
    "      \"tool_call_id\": \"call_1\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"{\\\"breed\\\": \\\"Black Labrador\\\"}\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"This looks like a Black Labrador.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def llm_raw(inputs):\n",
    "    return outputs\n",
    "\n",
    "\n",
    "llm_raw(inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

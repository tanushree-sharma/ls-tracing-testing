{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72ba22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e32e43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (1.0.0a14)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0a7 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langchain) (1.0.0a8)\n",
      "Requirement already satisfied: langgraph<2.0.0,>=1.0.0a4 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langchain) (1.0.0a4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (0.4.31)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (4.15.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langgraph<2.0.0,>=1.0.0a4->langchain) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt==0.7.0a2 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langgraph<2.0.0,>=1.0.0a4->langchain) (0.7.0a2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langgraph<2.0.0,>=1.0.0a4->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langgraph<2.0.0,>=1.0.0a4->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0a7->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph<2.0.0,>=1.0.0a4->langchain) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=1.0.0a4->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=1.0.0a4->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0a7->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0a7->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0a7->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=1.0.0a4->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=1.0.0a4->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=1.0.0a4->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=1.0.0a4->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=1.0.0a4->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0a7->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0a7->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/tanushreesharma/Documents/Projects/ls-tracing-testing/.venv/lib/python3.13/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<2.0.0,>=1.0.0a4->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --pre -U langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde45c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if we have the latest LangChain functionality\n",
    "# Even though version shows 1.0.0a13, we actually have 1.0.0a14 installed\n",
    "\n",
    "try:\n",
    "    from langchain.chat_models import init_chat_model\n",
    "    print(\"✅ init_chat_model is available (1.0.0a14 feature)\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ init_chat_model not available: {e}\")\n",
    "\n",
    "# Check if we have other 1.0.0a14 features\n",
    "try:\n",
    "    import langchain\n",
    "    # Check for new modules that might be in 1.0.0a14\n",
    "    if hasattr(langchain, 'chat_models'):\n",
    "        print(\"✅ langchain.chat_models module is available\")\n",
    "    else:\n",
    "        print(\"❌ langchain.chat_models module not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking features: {e}\")\n",
    "\n",
    "print(f\"\\nNote: Version string shows {langchain.__version__} but package is actually 1.0.0a14\")\n",
    "print(\"This is a known packaging issue with the pre-release version.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66684792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check LangChain version after kernel restart\n",
    "import langchain\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "\n",
    "# Verify we're using the updated version\n",
    "if langchain.__version__ == \"1.0.0a14\":\n",
    "    print(\"✅ Successfully updated to latest version!\")\n",
    "else:\n",
    "    print(f\"⚠️  Still on version {langchain.__version__}, expected 1.0.0a14\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1fa0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which Python environment the notebook is using\n",
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if we're in a virtual environment\n",
    "import os\n",
    "venv_path = os.environ.get('VIRTUAL_ENV')\n",
    "if venv_path:\n",
    "    print(f\"Virtual environment: {venv_path}\")\n",
    "else:\n",
    "    print(\"No virtual environment detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b53b837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 1.0.0a13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import langchain\n",
    "print(f\"LangChain version: {langchain.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage\n",
    "from langsmith import traceable\n",
    "import base64\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43514a65",
   "metadata": {},
   "source": [
    "# create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"anthropic:claude-3-7-sonnet-latest\",\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c84523",
   "metadata": {},
   "source": [
    "## Additional fields in inputs renders weird \n",
    "- Doesnt have the \"Additional fields\" callout like the output does\n",
    "- Shows up BEFORE the list of messages (should be after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ad2d2",
   "metadata": {},
   "source": [
    "# init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4.1\")\n",
    "llm.invoke(\"Why do parrots talk?\")\n",
    "\n",
    "model = init_chat_model(\"openai:gpt-4.1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f822054",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"id\": \"msg_123\",\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What breed is this dog?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image\",\n",
    "          \"source_type\": \"url\",\n",
    "          \"url\": \"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\",\n",
    "          \"mime_type\": \"image/jpeg\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "llm.invoke(inputs[\"messages\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af4a70d",
   "metadata": {},
   "source": [
    "# model_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather at a location.\"\"\"\n",
    "    return f\"It's sunny in {location}.\"\n",
    "\n",
    "\n",
    "model_with_tools = llm.bind_tools([get_weather])\n",
    "\n",
    "response = model_with_tools.invoke(\"What's the weather like in Boston?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a742cdc2",
   "metadata": {},
   "source": [
    "# structured outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e30625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Movie(BaseModel):\n",
    "    \"\"\"A movie with details.\"\"\"\n",
    "    title: str = Field(..., description=\"The title of the movie\")\n",
    "    year: int = Field(..., description=\"The year the movie was released\")\n",
    "    director: str = Field(..., description=\"The director of the movie\")\n",
    "    rating: float = Field(..., description=\"The movie's rating out of 10\")\n",
    "\n",
    "model_with_structure = llm.with_structured_output(Movie, include_raw=True)\n",
    "response = model_with_structure.invoke(\"Provide details about the movie Inception\")\n",
    "print(response)  # Movie(title=\"Inception\", year=2010, director=\"Christopher Nolan\", rating=8.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6f7d8",
   "metadata": {},
   "source": [
    "# tools and tool messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# After a model makes a tool call\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"args\": {\"location\": \"San Francisco\"},\n",
    "        \"id\": \"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunny, 72°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # Must match the call ID\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    HumanMessage(\"What's the weather in San Francisco?\"),\n",
    "    ai_message,  # Model's tool call\n",
    "    tool_message,  # Tool execution result\n",
    "]\n",
    "response = model.invoke(messages)  # Model processes the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd4071",
   "metadata": {},
   "source": [
    "# Content Blocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# String content\n",
    "messages = [HumanMessage(content_blocks=[\n",
    "    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image\", \"url\": \"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\"},\n",
    "])] \n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputs = [HumanMessage(content_blocks=[\n",
    "    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image\", \"url\": \"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\"},\n",
    "])] \n",
    "\n",
    "\n",
    "output_msg = AIMessage(\n",
    "    content=[\n",
    "        {\"type\": \"thinking\", \"thinking\": \"...\", \"signature\": \"WaUjzkyp...\"},\n",
    "        {\"type\": \"text\", \"text\": \"...\"},\n",
    "    ],\n",
    "    response_metadata={\"model_provider\": \"anthropic\"}\n",
    ")\n",
    "\n",
    "\n",
    "outputs = output_msg.content_blocks\n",
    "\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def llm_raw(inputs):\n",
    "    return outputs\n",
    "\n",
    "\n",
    "llm_raw(inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af4d5a8",
   "metadata": {},
   "source": [
    "## Content blocks rendering\n",
    "\n",
    "I think there's a gap in how we render content blocks: https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%2222select%22%3Atrue%2C%22id%22%3Atrue%2C%22status%22%3Atrue%2C%22name%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22start_time%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Atrue%2C%22last_queued_at%22%3Atrue%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Atrue%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22feedback_stats%22%3Atrue%2C%22reference_example_id%22%3Atrue%2C%22actions%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&peek=bdb7da3d-14ef-4257-aa8d-35ab9becc8a7&peeked_trace=bdb7da3d-14ef-4257-aa8d-35ab9becc8a7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca952daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"openai:gpt-4o\", output_version=\"v1\")\n",
    "resp = model.invoke(\"hello\")\n",
    "print (resp.content_blocks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b754b",
   "metadata": {},
   "source": [
    "# Multi-modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images\n",
    "\n",
    "image_url = \"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\"\n",
    "image_base64 = base64.standard_b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "inputs = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n",
    "        {\"type\": \"image\", \"url\": \"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# From base64 data\n",
    "output = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"base64\": image_base64,\n",
    "            \"mime_type\": \"image/jpeg\",\n",
    "        },\n",
    "    ]\n",
    "} \n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def llm_raw(inputs):\n",
    "    return output\n",
    "\n",
    "\n",
    "llm_raw(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e11d0",
   "metadata": {},
   "source": [
    "## Gap in image rendering \n",
    "\n",
    "We don't render images\n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%2222select%22%3Atrue%2C%22id%22%3Atrue%2C%22status%22%3Atrue%2C%22name%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22start_time%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Atrue%2C%22last_queued_at%22%3Atrue%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Atrue%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22feedback_stats%22%3Atrue%2C%22reference_example_id%22%3Atrue%2C%22actions%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&peek=7c87a2bd-fa0e-4aa0-b8b3-2719852a8757&peeked_trace=7c87a2bd-fa0e-4aa0-b8b3-2719852a8757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf\n",
    "\n",
    "pdf_url = \"https://pdfobject.com/pdf/sample.pdf\"\n",
    "pdf_base64 = base64.standard_b64encode(httpx.get(pdf_url).content).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "inputs = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this document.\"},\n",
    "        {\"type\": \"file\", \"url\": \"https://pdfobject.com/pdf/sample.pdf\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# From base64 data\n",
    "output = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this document.\"},\n",
    "        {\n",
    "            \"type\": \"file\",\n",
    "            \"base64\": pdf_base64,\n",
    "            \"mime_type\": \"application/pdf\",\n",
    "        },\n",
    "    ]\n",
    "} \n",
    "\n",
    "\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def llm_raw(inputs):\n",
    "    return output\n",
    "\n",
    "\n",
    "llm_raw(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b755cd",
   "metadata": {},
   "source": [
    "## Gap in redering PDFs\n",
    "\n",
    "Same issue with PDFs\n",
    "\n",
    "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/projects/p/5b35f59d-3a34-49d1-b6bb-b31d3cf45367?columnVisibilityModel=%7B%2222select%22%3Atrue%2C%22id%22%3Atrue%2C%22status%22%3Atrue%2C%22name%22%3Atrue%2C%22inputs%22%3Atrue%2C%22outputs%22%3Atrue%2C%22start_time%22%3Atrue%2C%22latency%22%3Atrue%2C%22in_dataset%22%3Atrue%2C%22last_queued_at%22%3Atrue%2C%22total_tokens%22%3Atrue%2C%22total_cost%22%3Atrue%2C%22first_token_time%22%3Atrue%2C%22tags%22%3Atrue%2C%22metadata%22%3Atrue%2C%22feedback_stats%22%3Atrue%2C%22reference_example_id%22%3Atrue%2C%22actions%22%3Atrue%7D&timeModel=%7B%22duration%22%3A%227d%22%7D&peek=1955e5c3-b539-4029-8321-25bb25a344b1&peeked_trace=1955e5c3-b539-4029-8321-25bb25a344b1\n",
    "\n",
    "Not going to try audio, video but likely the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import ToolNode, create_agent\n",
    "import random\n",
    "\n",
    "@tool\n",
    "def fetch_user_data(user_id: str) -> str:\n",
    "    \"\"\"Fetch user data from database.\"\"\"\n",
    "    if random.random() > 0.7:\n",
    "        raise ConnectionError(\"Database connection timeout\")\n",
    "    return f\"User {user_id}: John Doe, john@example.com, Active\"\n",
    "\n",
    "@tool\n",
    "def process_transaction(amount: float, user_id: str) -> str:\n",
    "    \"\"\"Process a financial transaction.\"\"\"\n",
    "    if amount > 10000:\n",
    "        raise ValueError(f\"Amount {amount} exceeds maximum limit of 10000\")\n",
    "    return f\"Processed ${amount} for user {user_id}\"\n",
    "\n",
    "def handle_errors(e: Exception) -> str:\n",
    "    if isinstance(e, ConnectionError):\n",
    "        return \"The database is currently overloaded, but it is safe to retry. Please try again with the same parameters.\"\n",
    "    elif isinstance(e, ValueError):\n",
    "        return f\"Error: {e}. Try to process the transaction in smaller amounts.\"\n",
    "    return f\"Error: {e}. Please try again.\"\n",
    "\n",
    "tool_node = ToolNode(\n",
    "    tools=[fetch_user_data, process_transaction],\n",
    "    handle_tool_errors=handle_errors\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    tools=tool_node,\n",
    "    prompt=\"You are a financial assistant.\"\n",
    ")\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Process a payment of 15000 dollars for user123. Generate a receipt email and address it to the user.\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cca00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Perform mathematical calculations.\"\"\"\n",
    "    return 99\n",
    "\n",
    "agent = create_agent(model, tools=[search, calculate])\n",
    "\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [SystemMessage(content=\"always prefer to use a tool if it is relevant to the user's query\"),\n",
    "    HumanMessage(content=\"what is 2 + 2?\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77160994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_in_the_loop_demo.py\n",
    "\n",
    "import json\n",
    "from typing import Any, Literal, Protocol\n",
    "\n",
    "# --- LangChain / LangGraph imports ---\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolCall, ToolMessage\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware.types import AgentMiddleware, AgentState\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.runtime import Runtime\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing_extensions import NotRequired, TypedDict\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1) Human-in-the-Loop middleware (your implementation)\n",
    "# =============================================================================\n",
    "\n",
    "class Action(TypedDict):\n",
    "    \"\"\"Represents an action with a name and arguments.\"\"\"\n",
    "    name: str\n",
    "    arguments: dict[str, Any]\n",
    "\n",
    "\n",
    "class ActionRequest(TypedDict):\n",
    "    \"\"\"Represents an action request with a name, arguments, and description.\"\"\"\n",
    "    name: str\n",
    "    arguments: dict[str, Any]\n",
    "    description: NotRequired[str]\n",
    "\n",
    "\n",
    "DecisionType = Literal[\"approve\", \"edit\", \"reject\"]\n",
    "\n",
    "\n",
    "class ReviewConfig(TypedDict):\n",
    "    \"\"\"Policy for reviewing a HITL request.\"\"\"\n",
    "    action_name: str\n",
    "    allowed_decisions: list[DecisionType]\n",
    "    arguments_schema: NotRequired[dict[str, Any]]\n",
    "\n",
    "\n",
    "class HITLRequest(TypedDict):\n",
    "    \"\"\"Request for human feedback on a sequence of actions requested by a model.\"\"\"\n",
    "    action_requests: list[ActionRequest]\n",
    "    review_configs: list[ReviewConfig]\n",
    "\n",
    "\n",
    "class ApproveDecision(TypedDict):\n",
    "    type: Literal[\"approve\"]\n",
    "\n",
    "\n",
    "class EditDecision(TypedDict):\n",
    "    type: Literal[\"edit\"]\n",
    "    edited_action: Action\n",
    "\n",
    "\n",
    "class RejectDecision(TypedDict):\n",
    "    type: Literal[\"reject\"]\n",
    "    message: NotRequired[str]\n",
    "\n",
    "\n",
    "Decision = ApproveDecision | EditDecision | RejectDecision\n",
    "\n",
    "\n",
    "class HITLResponse(TypedDict):\n",
    "    decisions: list[Decision]\n",
    "\n",
    "\n",
    "class _DescriptionFactory(Protocol):\n",
    "    def __call__(self, tool_call: ToolCall, state: AgentState, runtime: Runtime) -> str: ...\n",
    "\n",
    "\n",
    "class InterruptOnConfig(TypedDict):\n",
    "    \"\"\"Configuration for an action requiring human in the loop.\"\"\"\n",
    "    allowed_decisions: list[DecisionType]\n",
    "    description: NotRequired[str | _DescriptionFactory]\n",
    "    arguments_schema: NotRequired[dict[str, Any]]\n",
    "\n",
    "\n",
    "class HumanInTheLoopMiddleware(AgentMiddleware):\n",
    "    \"\"\"Human in the loop middleware.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        interrupt_on: dict[str, bool | InterruptOnConfig],\n",
    "        *,\n",
    "        description_prefix: str = \"Tool execution requires approval\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        resolved_configs: dict[str, InterruptOnConfig] = {}\n",
    "        for tool_name, tool_config in interrupt_on.items():\n",
    "            if isinstance(tool_config, bool):\n",
    "                if tool_config is True:\n",
    "                    resolved_configs[tool_name] = InterruptOnConfig(\n",
    "                        allowed_decisions=[\"approve\", \"edit\", \"reject\"]\n",
    "                    )\n",
    "            elif tool_config.get(\"allowed_decisions\"):\n",
    "                resolved_configs[tool_name] = tool_config\n",
    "        self.interrupt_on = resolved_configs\n",
    "        self.description_prefix = description_prefix\n",
    "\n",
    "    def _create_action_and_config(\n",
    "        self,\n",
    "        tool_call: ToolCall,\n",
    "        config: InterruptOnConfig,\n",
    "        state: AgentState,\n",
    "        runtime: Runtime,\n",
    "    ) -> tuple[ActionRequest, ReviewConfig]:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "\n",
    "        # Description can be a string or callable\n",
    "        description_value = config.get(\"description\")\n",
    "        if callable(description_value):\n",
    "            description = description_value(tool_call, state, runtime)\n",
    "        elif description_value is not None:\n",
    "            description = description_value\n",
    "        else:\n",
    "            description = f\"{self.description_prefix}\\n\\nTool: {tool_name}\\nArgs: {tool_args}\"\n",
    "\n",
    "        action_request = ActionRequest(\n",
    "            name=tool_name,\n",
    "            arguments=tool_args,\n",
    "            description=description,\n",
    "        )\n",
    "        review_config = ReviewConfig(\n",
    "            action_name=tool_name,\n",
    "            allowed_decisions=config[\"allowed_decisions\"],\n",
    "        )\n",
    "        return action_request, review_config\n",
    "\n",
    "    def _process_decision(\n",
    "        self,\n",
    "        decision: Decision,\n",
    "        tool_call: ToolCall,\n",
    "        config: InterruptOnConfig,\n",
    "    ) -> tuple[ToolCall | None, ToolMessage | None]:\n",
    "        allowed_decisions = config[\"allowed_decisions\"]\n",
    "\n",
    "        if decision[\"type\"] == \"approve\" and \"approve\" in allowed_decisions:\n",
    "            return tool_call, None\n",
    "\n",
    "        if decision[\"type\"] == \"edit\" and \"edit\" in allowed_decisions:\n",
    "            edited_action = decision[\"edited_action\"]\n",
    "            return (\n",
    "                ToolCall(\n",
    "                    type=\"tool_call\",\n",
    "                    name=edited_action[\"name\"],\n",
    "                    args=edited_action[\"arguments\"],\n",
    "                    id=tool_call[\"id\"],\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "\n",
    "        if decision[\"type\"] == \"reject\" and \"reject\" in allowed_decisions:\n",
    "            content = decision.get(\"message\") or (\n",
    "                f\"User rejected the tool call for `{tool_call['name']}` with id {tool_call['id']}\"\n",
    "            )\n",
    "            tool_message = ToolMessage(\n",
    "                content=content,\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "                status=\"error\",\n",
    "            )\n",
    "            return tool_call, tool_message\n",
    "\n",
    "        msg = (\n",
    "            f\"Unexpected human decision: {decision}. \"\n",
    "            f\"Decision type '{decision.get('type')}' \"\n",
    "            f\"is not allowed for tool '{tool_call['name']}'. \"\n",
    "            f\"Expected one of {allowed_decisions}.\"\n",
    "        )\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        \"\"\"Trigger interrupt flows for relevant tool calls after an AIMessage.\"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "        if not messages:\n",
    "            return None\n",
    "\n",
    "        last_ai_msg = next((m for m in reversed(messages) if isinstance(m, AIMessage)), None)\n",
    "        if not last_ai_msg or not last_ai_msg.tool_calls:\n",
    "            return None\n",
    "        \n",
    "        # ✅ NEW: If any earlier AI message already proposed tool calls,\n",
    "        # skip HITL (we only interrupt on the *first* tool-call round).\n",
    "        prior_ai_tool_msgs = [\n",
    "            m for m in messages\n",
    "            if isinstance(m, AIMessage) and (m is not last_ai_msg) and getattr(m, \"tool_calls\", None)\n",
    "        ]\n",
    "        if prior_ai_tool_msgs:\n",
    "            return None\n",
    "\n",
    "        interrupt_tool_calls: list[ToolCall] = []\n",
    "        auto_approved_tool_calls: list[ToolCall] = []\n",
    "\n",
    "        for tool_call in last_ai_msg.tool_calls:\n",
    "            (interrupt_tool_calls if tool_call[\"name\"] in self.interrupt_on\n",
    "             else auto_approved_tool_calls).append(tool_call)\n",
    "\n",
    "        if not interrupt_tool_calls:\n",
    "            return None\n",
    "\n",
    "        revised_tool_calls: list[ToolCall] = auto_approved_tool_calls.copy()\n",
    "        artificial_tool_messages: list[ToolMessage] = []\n",
    "\n",
    "        action_requests: list[ActionRequest] = []\n",
    "        review_configs: list[ReviewConfig] = []\n",
    "\n",
    "        for tool_call in interrupt_tool_calls:\n",
    "            cfg = self.interrupt_on[tool_call[\"name\"]]\n",
    "            action_request, review_config = self._create_action_and_config(\n",
    "                tool_call, cfg, state, runtime\n",
    "            )\n",
    "            action_requests.append(action_request)\n",
    "            review_configs.append(review_config)\n",
    "\n",
    "        hitl_request = HITLRequest(\n",
    "            action_requests=action_requests,\n",
    "            review_configs=review_configs,\n",
    "        )\n",
    "\n",
    "        resp = interrupt(hitl_request)\n",
    "    \n",
    "        # Some runtimes return a single response, others wrap it in a list.\n",
    "        if isinstance(resp, list):\n",
    "            if len(resp) != 1:\n",
    "                raise ValueError(f\"Expected exactly 1 HITLResponse, got {len(resp)}\")\n",
    "            resp = resp[0]\n",
    "        decisions = resp[\"decisions\"]\n",
    "\n",
    "\n",
    "        if (len(decisions)) != (len(interrupt_tool_calls)):\n",
    "            raise ValueError(\n",
    "                f\"Number of human decisions ({len(decisions)}) does not match \"\n",
    "                f\"number of hanging tool calls ({len(interrupt_tool_calls)}).\"\n",
    "            )\n",
    "\n",
    "        for i, decision in enumerate(decisions):\n",
    "            tool_call = interrupt_tool_calls[i]\n",
    "            cfg = self.interrupt_on[tool_call[\"name\"]]\n",
    "            revised_tool_call, tool_message = self._process_decision(decision, tool_call, cfg)\n",
    "            if revised_tool_call:\n",
    "                revised_tool_calls.append(revised_tool_call)\n",
    "            if tool_message:\n",
    "                artificial_tool_messages.append(tool_message)\n",
    "\n",
    "        last_ai_msg.tool_calls = revised_tool_calls\n",
    "        return {\"messages\": [last_ai_msg, *artificial_tool_messages]}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2) Tools\n",
    "# =============================================================================\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Perform mathematical calculations.\"\"\"\n",
    "    # Intentional value to make HITL visible when you edit/approve\n",
    "    # You can change to eval(expression) after testing.\n",
    "    return \"99\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3) Agent + Middleware + Checkpointer\n",
    "# =============================================================================\n",
    "\n",
    "# TODO: Replace with your real chat model, e.g.:\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "hitl = HumanInTheLoopMiddleware(\n",
    "    interrupt_on={\n",
    "        # Interrupt AFTER model proposes these tool calls\n",
    "        \"search\": True,\n",
    "        \"calculate\": True,\n",
    "    },\n",
    "    description_prefix=\"Pending approval:\",\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[search, calculate],\n",
    "    middleware=[hitl],\n",
    "    checkpointer=memory,\n",
    ")\n",
    "\n",
    "memory = InMemorySaver() \n",
    "thread_id = \"demo-thread-8\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4) Terminal-driven human review loop\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "def _normalize_interrupts(raw_interrupts):\n",
    "    \"\"\"Return a list of plain dict requests (unwraps Interrupt objects).\"\"\"\n",
    "    # Make it a list\n",
    "    items = raw_interrupts if isinstance(raw_interrupts, list) else [raw_interrupts]\n",
    "    out = []\n",
    "    for item in items:\n",
    "        # Unwrap Interrupt objects (they usually carry the payload in .value)\n",
    "        item = getattr(item, \"value\", item)\n",
    "        out.append(item)\n",
    "    return out\n",
    "\n",
    "def run_with_review(user_text: str):\n",
    "    result = agent.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                SystemMessage(content=\"always prefer to use a tool if it is relevant to the user's query\"),\n",
    "                HumanMessage(content=user_text),\n",
    "            ]\n",
    "        },\n",
    "        config={\n",
    "            \"configurable\": {\"thread_id\": thread_id},\n",
    "            \"checkpointer\": memory,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    while isinstance(result, dict) and \"__interrupt__\" in result:\n",
    "        raw_interrupts = result[\"__interrupt__\"]\n",
    "        requests = _normalize_interrupts(raw_interrupts)  # <-- key fix\n",
    "\n",
    "        responses = []\n",
    "        for req_idx, req in enumerate(requests, 1):\n",
    "            # req is now a plain dict (your HITLRequest): has keys action_requests, review_configs\n",
    "            actions = req.get(\"action_requests\", [])\n",
    "            print(\"\\n=== HUMAN REVIEW REQUIRED ===\")\n",
    "            print(f\"(interrupt #{req_idx} with {len(actions)} action(s))\")\n",
    "            for i, item in enumerate(actions, 1):\n",
    "                name = item[\"name\"]\n",
    "                args = item.get(\"arguments\")\n",
    "                desc = item.get(\"description\")\n",
    "                print(f\"[{i}] {name}  args={args}\")\n",
    "                if desc:\n",
    "                    print(f\"    desc: {desc}\")\n",
    "\n",
    "            print(\"\\nEnter actions comma-separated for THIS interrupt (approve|edit|reject). Example: approve,edit\")\n",
    "            choices = [c.strip().lower() for c in input(\"> \").split(\",\")]\n",
    "            if len(choices) != len(actions):\n",
    "                print(\"Count mismatch; defaulting any missing to 'approve'.\")\n",
    "                choices += [\"approve\"] * (len(actions) - len(choices))\n",
    "\n",
    "            decisions = []\n",
    "            for choice, item in zip(choices, actions):\n",
    "                if choice == \"approve\":\n",
    "                    decisions.append({\"type\": \"approve\"})\n",
    "                elif choice == \"edit\":\n",
    "                    print(f\"Enter edited tool name (or blank to keep '{item['name']}'):\")\n",
    "                    new_name = input(\"> \").strip() or item[\"name\"]\n",
    "                    print('Enter edited JSON args on one line (e.g., {\"expression\": \"2+2\"}):')\n",
    "                    raw = input(\"> \").strip() or \"{}\"\n",
    "                    try:\n",
    "                        new_args = json.loads(raw)\n",
    "                        if not isinstance(new_args, dict):\n",
    "                            raise ValueError(\"edited arguments must be a JSON object\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Invalid JSON ({e}); using empty object.\")\n",
    "                        new_args = {}\n",
    "                    decisions.append({\n",
    "                        \"type\": \"edit\",\n",
    "                        \"edited_action\": {\"name\": new_name, \"arguments\": new_args}\n",
    "                    })\n",
    "                elif choice == \"reject\":\n",
    "                    print(\"Enter a short rejection message:\")\n",
    "                    msg = input(\"> \").strip() or \"Rejected by human reviewer.\"\n",
    "                    decisions.append({\"type\": \"reject\", \"message\": msg})\n",
    "                else:\n",
    "                    decisions.append({\"type\": \"approve\"})\n",
    "\n",
    "            responses.append({\"decisions\": decisions})\n",
    "\n",
    "        # Resume with one HITLResponse per interrupt request (order matters)\n",
    "        result = agent.invoke(\n",
    "            Command(resume=responses),\n",
    "            config={\n",
    "                \"configurable\": {\"thread_id\": thread_id},\n",
    "                \"checkpointer\": memory,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    if isinstance(result, AIMessage):\n",
    "        print(\"\\n=== FINAL ===\")\n",
    "        print(result.content)\n",
    "    else:\n",
    "        print(\"\\n=== FINAL (dict) ===\")\n",
    "        print(result)\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5) Run\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example prompt that should trigger a tool call (and thus an interrupt)\n",
    "    run_with_review(\"what is 2 + 2?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
